\chapter{Introduction}
\label{cha:section_introduction}
Robustly fitting a statistical model to data is a task ubiquitous to practically all data-driven fields, but the more nonlinear, uncertain and/or scattered the dataset is, the more difficult this task becomes. In the common case of two dimensional models (i.e. one independent variable $x$ and one dependent variable $y(x)$), datasets with intrinsic uncertainties, or error bars, along both $x$ and $y$ prove difficult to fit to in general, and if the dataset has some \textit{extrinsic} uncertainty/scatter (i.e., sample variance) that cannot be accounted for solely by the error bars, the difficulty increases still.

In this work, I describe a new, easily generalizable statistic developed by \textcite{trotter}, the Trotter-Reichart-Konz statistic---hereafter the TRK statistic---that is used to fit models to data in such ``worst case'' scenarios. Such model \textit{distributions} are defined by convolving a model curve $y_c(x;\vartheta_m)$ that describes the shape of the model with a 2D probability distribution that characterizes the scatter of the data, where $\vartheta_m$ is the set of parameters describing the model. In order to fit such a model to a set of data, values for $\vartheta_m$ and the parameters that describe the extrinsic scatter of the dataset must be determined that maximize the joint probability, or likelihood, of the model curve and the dataset; in other words, a model distribution must be found that is \textit{most likely} to reproduce the dataset. Assuming that the intrinsic and extrinsic uncertainties are Gaussian (possibly asymmetric), I show how to define such a likelihood function following \textcite{trotter}. This likelihood includes integrating over a rotated coordinate system of choice, and when a specific set of coordinates is used, it results in a statistic that is invertible (i.e. fitting $x$ vs. $y$ will result in the same fit as $y$ vs $x$), computationally feasible, and reduces to a $\chi^2$ statistic in the classic 1D uncertainty case; we define this as the TRK statistic. Models predicted by maximizing the TRK statistic's likelihood function are geometrically equivalent to models that minimize the sum of the squares of the radial distances of each datapoint centroid from the model curve, which I demonstrate. The TRK statistic is not \textit{scalable}, i.e. it yields different best fits depending on the choice of basis, or \textit{scale} for each coordinate axis, with some optimum scale corresponding to the true best fit. However, I present an implementation of an algorithm originally conceptualized in \textcite{trotter} that can determine such an optimum scale, effectively removing this caveat of the TRK statistic. 

The original introduction of the TRK statistic in \textcite{trotter} used a genetic algorithm-based implementation of the statistic that was non-automated, non-``production style'' code that only demonstrated the proof-of-concept of the statistic, rather than introduced an easy-to-use, widely applicable codebase. Because of this, my contribution to TRK was to implement the statistic from scratch into a fully-fledged, general nonlinear fitting suite that can be picked up and used easily by anyone, while supporting a number of features. This codebase is the focus of this work, and can be found, with documentation, at \url{https://skynet.unc.edu/rcr/calculator/downloads}.

In \S\ref{cha:TRK} and \S\ref{cha:properties} I introduce the TRK statistic and its central properties, closely following \textcite{trotter}. Following this, in \S\ref{cha:code1} I introduce the core algorithms used to perform fits and other procedures with the TRK statistic in practice, including, but not limited to, fit scale optimization, determining best fits, and model parameter distribution generation. Then, in \S\ref{cha:code2} I introduce additional algorithms of the TRK suite, including methods for the removal of correlation between model parameters, and the addition of asymmetric extrinsic and/or intrinsic uncertainties.

In \S\ref{cha:applic} I begin by comparing the TRK suite to similar algorithms (\S\ref{sec:compare}), and then present TRK fits used to model relationships between empirical parameters that describe the extinction of light by dust in the Milky Way as examples of the usage of the suite (\S\ref{sec:extincfits}). Next, I present a robust but easy-to-use implementation of the algorithm into a webpage-based calculator that I developed end-to-end (\S\ref{sec:website}), which can be used for quick, reliable fitting while also possessing a number of features. Finally, in \S\ref{cha:future} I discuss potential expansions of the suite that may be explored in later works.
% Immense applications to many fields

% Not much user input required