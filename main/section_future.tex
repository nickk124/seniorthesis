\chapter{Future Endeavors}
\label{cha:future}

\section{A Scale Optimization Algorithm for Asymmetric Uncertainties}
Continuing from \S\ref{sec:asymm}, the final consideration to be made involving the introduction of asymmetric error bars and/or slop is the \textit{fit scale optimization} algorithm described in \S\ref{sec:scaleop}. Recall that in the symmetric case, this involves
\begin{enumerate}
    \item determining the minimum scale $s=a$ where $\sigma_x\rightarrow 0$, and the maximum scale $s=b$ where $\sigma_y\rightarrow 0$, and
    \item determining the optimum fitting scale $s_0\in [a,b]$ by iteratively solving Equation \eqref{eq:r2TRK}.
\end{enumerate}
However, in the asymmetric case there are \textit{two} slop parameters along each dimension, so determining, or even qualifying, the minimum, maximum and optimum scales is nontrivial. I have attempted and/or posited a few potential methods of asymmetric scale optimization, and tested the scale-dependent best fit behavior of asymmetric fits, but the results have been inconclusive to date. As such, this issue remains as a future endeavor that will be explored in a later work.

\section{Support for $N$-dimensional Models}
For any statistic, it is desirable to be able to fit models to data with \textit{multiple} independent (``$x$'') variables. I have considered the possibility of generalizing the TRK statistic to $N-1$ independent variables (so $N$ dimensions total) such that each datapoint could have $N$ symmetric error bars, or up to $2N$ asymmetric error bars, and the model would have $N$ parameters describing slop/extrinsic scatter. However, there are a number of practical issues that could make this leap difficult, or potentially intractable. First, the tangent-point finding algorithm of \S\ref{sec:tgtpts} and \S\ref{sec:tgtfinder}, that is required to simply evaluate the TRK likelihood of Equation \eqref{eq:TRK}, would require determining where some $N-$dimensional model curve is tangent to an $N-$dimensional error hyperellipsoid, which would not only conceivably greatly increase the computational power and possible issues with the method, but would require a totally new algorithm to account for the arbitrary number of dimensions. Even more fundamentally, the scale optimization routine of \S\ref{sec:scaleop} would also have to be completely revamped, as not only is it entirely based off of 2-dimensional principles and algorithms, but the definition itself of fitting scale would have to change with addition of more dimensions, as adding $N$ dimensions means there are now $N$ possible ways to scale the dataset, described by $N$ additional scale parameters. Overall, while an $N-$dimensional TRK statistic and algorithm would be extremely useful, and practically the ultimate general ``worst-case'' dataset model-fitting tool, developing it would likely prove to be very challenging, if even possible.

\section{Python Implementation}
I developed the TRK suite in C++ due to the language's portability, low-level nature, and access to parallelization, to name a few reasons. However, Python is one of the most popular and widespread languages used within data science, the natural sciences, and other related statistically-based fields. Some of the most used model fitting algorithms are found within the many scientific Python libraries, such as SciPy (e.g. \textcite{2020SciPy-NMeth}), and introducing the TRK suite to Python could make it accessible and useful to many more people, and make it possible to integrate and use the TRK statistic with many other Python codebases. As such, another long-term goal of this project is to develop/port the TRK suite into a standalone Python library. This could be done in many ways, but the main option I am currently considering is using SWIG (Simple Wrapper Interface Generator of \textcite{beazley1996swig}) to wrap the C++ TRK code into Python, which I did at a basic level when developing the TRK calculator, as the website runs on a Python-based framework.
